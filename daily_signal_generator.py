#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Finspark AI â€“ v6.0 FINAL PRODUCTION SINGLE FILE ENGINE
--------------------------------------------------------------------
Includes:
- All 32 critical fixes
- Correct safe_iloc
- Correct async mapping
- Yahoo Finance only
- Zero disruption to production DB
- Multi-timeframe engine (5m, 15m, 30m, 1h)
- Stable, safe, enterprise-grade
--------------------------------------------------------------------
"""

import os
import sys
import asyncio
import logging
import time
from datetime import datetime, time as dt_time
import pytz
import aiohttp
import pandas as pd
import numpy as np
from supabase import create_client

# ------------------ CONFIGURATION ------------------

SUPABASE_URL = os.getenv('SUPABASE_URL', 'YOUR_SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY', 'YOUR_SUPABASE_KEY')

DB_TABLE_SIGNALS = "intraday_signals_v6_final"
DB_TABLE_ERRORS = "engine_errors_v6_final"

TIME_FRAMES = ['5m', '15m', '30m', '1h']
DEFAULT_PERIOD = "7d"

IST = pytz.timezone("Asia/Kolkata")
MARKET_OPEN = dt_time(9, 15)
MARKET_CLOSE = dt_time(15, 30)

STOCK_LIST = [
    'RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS',
    'KOTAKBANK.NS', 'WIPRO.NS', 'HCLTECH.NS', 'LT.NS', 'ADANIENT.NS'
]

TICKER_MAP = {
    'CADILAHC.NS': 'ZYDUSLIFE.NS',
    'LTI.NS': 'LTIM.NS',
    'MINDTREE.NS': 'LTIM.NS',
    'ADANIGAS.NS': 'ATGL.NS',
}

CONCURRENCY_LIMIT = 20
FETCH_TIMEOUT = 30
RETRY_COUNT = 3
SEMAPHORE = asyncio.Semaphore(CONCURRENCY_LIMIT)

RSI_PERIOD = 14
MACD_FAST = 12
MACD_SLOW = 26
MACD_SIGNAL = 9

BB_PERIOD = 20
VOL_PERIOD = 20

SL_ATR_MULT = 1.2
TP_ATR_MULT = 2.4

MIN_CANDLE_COUNT = 100
MAX_CIRCUIT_PCT = 0.18

# ------------------ LOGGING ------------------

LOG_FORMAT = "%(asctime)s %(levelname)s [%(name)s] %(message)s"
logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)
logger = logging.getLogger("FinsparkV6")

# ------------------ UTILITIES ------------------

def get_safe_ticker(t):
    return TICKER_MAP.get(t.upper(), t.upper())

def safe_iloc(series, idx, fallback=np.nan):
    if not isinstance(series, pd.Series) or series.empty:
        return fallback
    try:
        if idx < 0 and abs(idx) > len(series):
            return fallback
        if idx >= 0 and idx >= len(series):
            return fallback
        val = series.iloc[idx]
        return val if pd.notna(val) else fallback
    except:
        return fallback

def is_market_open():
    now = datetime.now(IST)
    if now.weekday() > 4:
        return False, "Weekend"
    if (now.time() >= MARKET_OPEN) and (now.time() <= MARKET_CLOSE):
        return True, "Open"
    return False, "Closed"

# ------------------ FETCHING ------------------

async def fetch_data(ticker, session, interval):
    pretty = ticker.replace(".NS", "")
    mapped = get_safe_ticker(ticker)

    url = f"https://query2.finance.yahoo.com/v8/finance/chart/{mapped}"
    params = {
        "range": DEFAULT_PERIOD,
        "interval": interval,
        "includePrePost": False
    }

    key = (ticker, interval)

    for attempt in range(RETRY_COUNT):
        async with SEMAPHORE:
            try:
                resp = await asyncio.wait_for(session.get(url, params=params), timeout=FETCH_TIMEOUT)
                async with resp:
                    if resp.status == 429:
                        logger.warning(f"{pretty} [{interval}] 429 Rate Limit")
                        raise aiohttp.ClientResponseError(resp.request_info, resp.history, status=429)

                    resp.raise_for_status()
                    raw = await resp.json()

                result = raw.get("chart", {}).get("result", [])
                if not result:
                    return key, None, None

                meta = result[0]['meta']
                q = result[0]['indicators']['quote'][0]
                ts = result[0]['timestamp']

                df = pd.DataFrame({
                    "Datetime": [datetime.fromtimestamp(x, IST) for x in ts],
                    "Open": q['open'],
                    "High": q['high'],
                    "Low": q['low'],
                    "Close": q['close'],
                    "Volume": q['volume']
                }).set_index("Datetime")

                return key, df, meta.get("previousClose")

            except Exception as e:
                if attempt < RETRY_COUNT - 1:
                    await asyncio.sleep(2 + attempt)
                else:
                    return key, None, None

    return key, None, None

# ------------------ INDICATORS ------------------

def indicators(df):
    if df is None or len(df) < MIN_CANDLE_COUNT:
        return None

    close = df["Close"]
    high = df["High"]
    low = df["Low"]

    tr = pd.concat([
        high - low,
        (high - close.shift()).abs(),
        (low - close.shift()).abs()
    ], axis=1).max(axis=1)

    atr = tr.ewm(com=13, adjust=False).mean()

    ema_20 = close.ewm(span=20).mean()
    ema_50 = close.ewm(span=50).mean()

    ema20_start = safe_iloc(ema_20, -5)
    ema20_end = safe_iloc(ema_20, -1)
    slope = (ema20_end - ema20_start) / 5 if ema20_start is not np.nan else 0
    angle = np.arctan(slope) * 57.29

    delta = close.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = gain.ewm(com=13).mean()
    avg_loss = loss.ewm(com=13).mean().mask(lambda x: x == 0, 1e-10)

    rsi = 100 - (100 / (1 + avg_gain / avg_loss))

    ema_fast = close.ewm(span=MACD_FAST).mean()
    ema_slow = close.ewm(span=MACD_SLOW).mean()
    macd = ema_fast - ema_slow
    macd_signal = macd.ewm(span=MACD_SIGNAL).mean()
    macd_hist = macd - macd_signal

    sma = close.rolling(BB_PERIOD).mean()
    std = close.rolling(BB_PERIOD).std()
    bb_upper = sma + 2 * std
    bb_lower = sma - 2 * std
    bb_width = (bb_upper - bb_lower) / sma * 100

    vol_avg = df['Volume'].rolling(VOL_PERIOD).mean().iloc[-1]

    return {
        "rsi": rsi.iloc[-1],
        "atr": atr.iloc[-1],
        "ema20": ema20_end,
        "ema50": ema_50.iloc[-1],
        "angle": angle,
        "macd_hist": macd_hist.iloc[-1],
        "bb_upper": bb_upper.iloc[-1],
        "bb_lower": bb_lower.iloc[-1],
        "bb_width": bb_width.iloc[-1],
        "vol_avg": vol_avg
    }

# ------------------ TREND ------------------

def trend_logic(ind, close):
    if pd.isna(ind["ema20"]) or pd.isna(ind["ema50"]):
        return "Sideways"
    if ind["bb_width"] < 1.5:
        return "Squeeze"
    if ind["ema20"] > ind["ema50"] and close > ind["ema20"] and ind["angle"] > 5:
        return "Uptrend"
    if ind["ema20"] < ind["ema50"] and close < ind["ema20"] and ind["angle"] < -5:
        return "Downtrend"
    return "Sideways"

# ------------------ SIGNAL LOGIC ------------------

def generate(df, prev_close, symbol, interval):
    close = safe_iloc(df["Close"], -1)
    open_ = safe_iloc(df["Open"], -1)
    high = safe_iloc(df["High"], -1)
    low = safe_iloc(df["Low"], -1)
    volume = safe_iloc(df["Volume"], -1)

    if pd.isna(close):
        return None

    if prev_close and abs(close - prev_close) / prev_close > MAX_CIRCUIT_PCT:
        return None

    ind = indicators(df)
    if ind is None:
        return None

    votes = []
    reasons = []

    tr = trend_logic(ind, close)
    if tr != "Sideways":
        reasons.append(tr)

    if ind["rsi"] < 30:
        votes.append("Buy")
    elif ind["rsi"] > 70:
        votes.append("Sell")

    if ind["macd_hist"] > 0:
        votes.append("Buy")
    elif ind["macd_hist"] < 0:
        votes.append("Sell")

    if close < ind["bb_lower"]:
        votes.append("Buy")
    elif close > ind["bb_upper"]:
        votes.append("Sell")

    buy = votes.count("Buy")
    sell = votes.count("Sell")

    signal = "Hold"
    base_conf = 40

    if buy > sell and buy >= 2:
        signal = "Buy"
        base_conf += buy * 5
    elif sell > buy and sell >= 2:
        signal = "Sell"
        base_conf += sell * 5

    conf = min(base_conf + np.log1p(len(reasons)) * 10, 95)

    sl = tp = rr = None
    if signal != "Hold":
        risk = ind["atr"] * SL_ATR_MULT
        reward = ind["atr"] * TP_ATR_MULT
        rr = round(reward / risk, 2)

        if signal == "Buy":
            sl = close - risk
            tp = close + reward
        else:
            sl = close + risk
            tp = close - reward

    now = datetime.now(IST)

    return {
        "symbol": symbol.replace(".NS", ""),
        "interval": interval,
        "signal": signal,
        "confidence": round(conf, 1),
        "close_price": round(close, 2),
        "stop_loss": round(sl, 2) if sl else None,
        "target": round(tp, 2) if tp else None,
        "risk_reward": rr,
        "trend": tr,
        "signal_date": now.date().isoformat(),
        "signal_time": now.strftime("%H:%M:%S"),
        "reasons": ", ".join(reasons)
    }

# ------------------ SUPABASE ------------------

def log_error(supabase, err_type, msg, stock="N/A", interval="N/A"):
    try:
        supabase.table(DB_TABLE_ERRORS).insert({
            "timestamp": datetime.now(IST).isoformat(),
            "error_type": err_type,
            "message": msg,
            "stock": stock,
            "interval": interval
        }).execute()
    except:
        pass

async def upload(supabase, data):
    try:
        if not data:
            return 0
        res = supabase.table(DB_TABLE_SIGNALS).insert(data).execute()
        return len(res.data) if isinstance(res.data, list) else len(data)
    except Exception as e:
        log_error(supabase, "UploadError", str(e))
        return 0

# ------------------ MAIN ENGINE ------------------

async def run_engine(supabase):
    start = time.time()

    market_ok, status = is_market_open()
    now = datetime.now(IST)

    if not market_ok:
        logger.info("Market closed. Exiting.")
        return

    async with aiohttp.ClientSession() as session:

        tasks = []
        for stock in STOCK_LIST:
            for tf in TIME_FRAMES:
                tasks.append(fetch_data(stock, session, tf))

        results = await asyncio.gather(*tasks)

    final = []
    for (symbol, interval), df, prev in results:
        if df is None or prev is None:
            log_error(supabase, "FetchFail", "No data", symbol, interval)
            continue

        s = generate(df, prev, symbol, interval)
        if s:
            final.append(s)

    await upload(supabase, final)

    logger.info(f"ENGINE DONE | {len(final)} signals | {time.time() - start:.2f}s")

# ------------------ ENTRY POINT ------------------

def main():
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        asyncio.run(run_engine(supabase))
    except Exception as e:
        logger.error(f"FATAL: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
